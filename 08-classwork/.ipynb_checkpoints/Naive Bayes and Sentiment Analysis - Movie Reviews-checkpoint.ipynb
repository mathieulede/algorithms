{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our own sentiment analysis\n",
    "\n",
    "But we're going to do it differently this time! Not just a list of pre-programmed words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in our data\n",
    "\n",
    "Lots of docs? `glob.glob`, same as always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Go into reviews, then go into txt_sentoken,\n",
    "# then go into BOTH 'pos' and 'neg' directories\n",
    "# then get every text file inside of there\n",
    "filenames = glob.glob(\"reviews/txt_sentoken/*/*.txt\")\n",
    "content = [open(filename).read() for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'content': content\n",
    "})\n",
    "\n",
    "# Let's see them\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sentiment is in the filename, let's extract it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract out the sentiment from the filename\n",
    "df['sentiment'] = df.filename.str.extract(\"txt_sentoken/(.*)/cv\", expand=False)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are we doing? An introduction to CLASSIFICATION.\n",
    "\n",
    "We have a bunch of movie reviews in categories. Maybe someone sends us a new review, what category does the new review belong in?\n",
    "\n",
    "We're going to train a classifier to recognize positive and negative reviews, so that if someone sends us a new review, we'll know if it's something we want to see without having to actually read the review.\n",
    "\n",
    "RULE IS: For classification algorithms, YOU MUST HAVE CATEGORIES ON YOUR ORIGINAL DATASET.\n",
    "\n",
    "**For clustering**\n",
    "\n",
    "1. You'll get a lot of documents\n",
    "2. You feed it to an algorithm, tell it create `x` number of categories\n",
    "3. The machine gives you back categories whether they make sense or not\n",
    "\n",
    "**For classification (which we are doing now)**\n",
    "\n",
    "1. You'll get a lot of documents\n",
    "2. You'll classify some of them into categories that you know and love\n",
    "3. You'll ask the algorithm what categories a new bunch of unlabeled documents end up in\n",
    "\n",
    "All mean the same thing: CATEGORY = CLASS = LABEL\n",
    "\n",
    "The reason why you use machine learning is to not do things manually. So if you can do things manually, do it. Otherwise just try different algorithms until one works well (but you might need to know some upsides or downsides of each to interpret that).\n",
    "\n",
    "# Why do we want to classify anything?\n",
    "\n",
    "Hmmmm, maybe to [identify fake news](http://www.fakenewschallenge.org/) without reading every story ever?\n",
    "\n",
    "# How are we classifying? NAIVE BAYES.\n",
    "\n",
    "## How does Naive Bayes work?\n",
    "\n",
    "NAIVE BAYES WORKS WITH TEXT (kind of)\n",
    "\n",
    "**Bayes Theorem (kind of)**\n",
    "\n",
    "* If you see a word that is normally in a spam email, there's a higher chance it's spam\n",
    "* If you see a word that is normally in a non-spam email, there's a higher chance it's not spam\n",
    "\n",
    "**Naive:** every word/feature/etc is independent of any other word\n",
    "\n",
    "FOR US: If you see words that are normally in positive reviews, it's probably a positive review.\n",
    "\n",
    "Secret trick: you can't just use text, you have to convert into numbers (vectorization to the rescue)\n",
    "\n",
    "## Types of Naive Bayes\n",
    "\n",
    "Naive Bayes works on words, and SOMETIMES your text is long and SOMETIMES your text is short.\n",
    "\n",
    "**Multinominal Naive Bayes - (multiple numbers)**: You count the words. You care about whether a word appears once or twice or three times or ten times. *This is better for long passages*\n",
    "\n",
    "**Bernoulli Naive Bayes - True/False Bayes:** You only care if the word shows up (`True`) or it doesn't show up (`False`) - *this is better for short passages*\n",
    "\n",
    "What kind of Bayes should we use this time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing our data (2 steps)\n",
    "\n",
    "Remember, machine learning **only likes numbers**, so we need to jump through some hoops first.\n",
    "\n",
    "## Prep 1: Convert our labels into numbers\n",
    "\n",
    "Our labels are only `neg` and `pos`, so maybe we could just make positive 1 and negative 0?\n",
    "\n",
    "This is a way to do it if you like being fancy and manually doing things..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_label(row):\n",
    "    if row.sentiment == \"WWWHHHAAAATTTT??????\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['sentiment_label'] = df.apply(make_label, axis=1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...but with 0/1 it's really easier to say \"sentiment, are you positive?\" and get `True` and `False` and then use `.astype(int)` to convert it to `0`/`1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['sentiment_label'] = (df.sentiment == 'pos').astype(int)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation 2: we need to build our list of features\n",
    "\n",
    "That's going to be our **list of words**. Same vectorizer thing we **always use**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(stop_words='english')\n",
    "matrix = vec.fit_transform(df.content)\n",
    "words_df = pd.DataFrame(matrix.toarray(), columns=vec.get_feature_names())\n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using our classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 1: Import and create the classifier\n",
    "\n",
    "What kind of Bayes classifier are we going to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "clf = WWWHHAAATTTTT????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Training the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teaching a classifier is called **training** or **fitting**. The classifier needs us to give it two things:\n",
    "    \n",
    "* **Our training features**: what the words are\n",
    "* **Our training labels**: whether it's positive or negative\n",
    "\n",
    "### What are our features?\n",
    "\n",
    "Remember, numbers only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are our labels?\n",
    "\n",
    "Remember, numbers only!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's actually train/teach/fit our classifier\n",
    "\n",
    "Remember, this is called **fitting**, so it's going to be `clf.fit`. We'll also refer to it as training or maybe even teaching.\n",
    "\n",
    "* First parameter is the **features**\n",
    "* Second parameter is the **labels**\n",
    "\n",
    "So easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No errors = we did a good job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Using the classifier\n",
    "\n",
    "Now that we trained it, how do we use it? Well, the point of a classifier is to **process new content to see which category it belongs in**, so let's get some new content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"I hate this movie it's terrible it's no good at all\",\n",
    "    \"I love this directory his movies are great\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1: Preparing our incoming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember when we did `vec.fit_transform`? That had the vectorizer learn all of the words (fit) and then count all the words (transform). Since it's already memorized all of the words that went into the classifier, we don't want to teach it any new ones - we just want it to count some new sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Predicting our incoming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have another matrix, we can use `clf.predict` to predict the labels for our sentences. We have to give it the **matrix**, though, since it doesn't understand words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That `[0,1]` matches up with our labels - it means the first one is negative and the second one is positive. What words does it use to decide? **Use this cut-and-pasted code!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "class_labels = ['pos', 'neg']\n",
    "feature_names = vec.get_feature_names()\n",
    "for i, class_label in enumerate(class_labels):\n",
    "    try:\n",
    "        top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "        features_names = vec.get_feature_names()\n",
    "        print(\"%s: %s\" % (class_label, \" \".join(features_names[j] for j in top10)))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Testing our classifier\n",
    "\n",
    "The big question here is **but is our classifier actually any good?**\n",
    "\n",
    "Even though we **built** a classifier, that doesn't actually **mean anything.** Maybe it's horrible. How can we test it?\n",
    "\n",
    "It'd be cheating if we tested it against something it already knew, so we need to get a little fancier than that.\n",
    "\n",
    "### Step 4.1: Preparating our split\n",
    "\n",
    "I always call this test/train split and then type it wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_test_split will split our data into two parts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting into...\n",
    "# X = are all our features\n",
    "# y = are all our labels\n",
    "# X_train are our features to train on (80%)\n",
    "# y_train are our labels to train on (80%)\n",
    "# X_test are our features to test on (20%)\n",
    "# y_train are our labels to test on (20%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    words_df.values, \n",
    "    df.sentiment_label, \n",
    "    test_size=0.2) \n",
    "\n",
    "# the first parameter is our FEATURES. can't just do words_df, it won't work :(\n",
    "# the second parameter is the LABEL as a number (so 0/1, not neg/pos)\n",
    "# 80% training, 20% testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do those variables look like?\n",
    "\n",
    "What are `X_train` and `X_test`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are `y_train` and `y_test`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2: Fitting and scoring against our test data\n",
    "\n",
    "Now we'll fit again with **only our training data**, then test it against the **testing data** with `clf.score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we're at it, how does it do with things it's already seen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about other classifiers?\n",
    "\n",
    "There are a handful of other classifiers, and some might be better! While there are general rules about what kind to use, usually you just switch around until you get the best performance. We'll go more in-depth next week, but let's play around with one for now.\n",
    "\n",
    "## Decision Trees\n",
    "\n",
    "This is a simple one to understand called a **decision tree**, they're usually pretty good.\n",
    "\n",
    "### Step 1: Import and create the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# Let's add max_depth=3 before we draw!\n",
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train and score the new classifier\n",
    "\n",
    "We have fewer steps this time because we've already **converted our data to numbers**, done our splits and all of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, they might not be that good **this** time, but how does it do on data it's already seen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What a wreck! This is called **overfitting** and we'll, yes, talk about it more next week.\n",
    "\n",
    "### Step 3: Understanding\n",
    "\n",
    "As a reward for your hard work, let's draw a pretty picture. We'll need to **remake the classifier so it can be drawn** - go up and change the classifier to `clf = tree.DecisionTreeClassifier(max_depth=3)` and re-run the fitting and scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pydotplus\n",
    "from IPython.display import Image  \n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "    feature_names=vec.get_feature_names(),  \n",
    "    class_names=clf.classes_.astype(str),  \n",
    "    filled=True, rounded=True,  proportion=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Epilogue\n",
    "\n",
    "Let's read some [fake news challenge code](https://github.com/FakeNewsChallenge/fnc-1-baseline/blob/master/feature_engineering.py)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
