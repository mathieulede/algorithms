{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "df = pd.read_csv(\"wine-reviews.csv\")\n",
    "df['alcohol_int'] = df.alcohol.str.extract(\"(\\d+)\", expand=False).dropna().astype(int)\n",
    "df['price_int'] = df.price.str.extract(\"(\\d+)\", expand=False).dropna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3131, 6166) (783, 6166) (3131,) (783,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "#clean up data\n",
    "df.dropna(subset = ['price_int', 'wine_desc'], how = 'any', inplace = True)\n",
    "\n",
    "#token pattern changed from '\\b\\w\\w+\\b' (default) to '\\b[a-zA-Z][a-zA-Z]+\\b' to avoid data leak.\n",
    "#If the price were in the review, that would be easy to classify.\n",
    "vec = CountVectorizer(stop_words = 'english', token_pattern=r'\\b[a-zA-Z][a-zA-Z]+\\b')\n",
    "vec.fit(df['wine_desc'])\n",
    "X = vec.transform(df['wine_desc'])\n",
    "y = df['price_int']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on train: 0.999999999945 \n",
      "Mean Squared Error on train: 4.68084469366e-08\n",
      "R2 on test: -0.846137875035 \n",
      "Mean Squared Error on test: 1298.29550531\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import  mean_squared_error, r2_score\n",
    "\n",
    "lr = LinearRegression(fit_intercept = 0)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print('R2 on train:', r2_score(y_train, lr.predict(X_train)), \n",
    "      '\\nMean Squared Error on train:', mean_squared_error(y_train, lr.predict(X_train)))\n",
    "\n",
    "print('R2 on test:', r2_score(y_test, lr.predict(X_test)), \n",
    "      '\\nMean Squared Error on test:', mean_squared_error(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier is great for interpolation, ie predicting prices based on reviews which lie within the set of reviews the model was trained on.  This is due to the varied vocabulary of the sommelier.  The model fails to extrapolate to the test set, also due to the varied nature of the vocabulary.  A negative R2 score reported by sklearn means the model performs arbitrarily worse than the mean price predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest Contributors to High Price\n",
      "\n",
      "alpine 64.2668179491\n",
      "seriously 69.8956331282\n",
      "individual 70.2345560249\n",
      "powerhouse 72.9926056999\n",
      "hallowed 74.7463065432\n",
      "ability 78.4165984052\n",
      "constructed 79.7706834233\n",
      "blockbuster 92.5654515964\n",
      "parcel 96.3371734782\n",
      "maintaining 107.994797587\n",
      "\n",
      "\n",
      "Largest Contributors to Low Price\n",
      "\n",
      "falls -39.2061883452\n",
      "amber -39.6222340231\n",
      "oodles -40.0331896038\n",
      "monolithic -41.478531196\n",
      "paso -41.5149207827\n",
      "twice -42.5507793016\n",
      "soaks -43.5891150345\n",
      "radiant -44.2865491428\n",
      "requisite -44.9345115271\n",
      "coolly -48.6337853171\n",
      "metallic -58.2305545734\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    print('\\n--------------------------------\\n')\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % (topic_idx+1))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "n = 10        \n",
    "bottom_n = np.argsort(lr.coef_)[n::-1]\n",
    "top_n = np.argsort(lr.coef_)[-n:]\n",
    "\n",
    "feature_names = vec.get_feature_names()\n",
    "\n",
    "print('Largest Contributors to High Price\\n')\n",
    "print(\"\\n\".join(feature_names[i] + \" \" + str(lr.coef_[i]) for i in top_n))\n",
    "\n",
    "print('\\n\\nLargest Contributors to Low Price\\n')\n",
    "print(\"\\n\".join(feature_names[i] + \" \" + str(lr.coef_[i]) for i in bottom_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
