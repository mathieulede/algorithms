{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our data\n",
    "\n",
    "### Step 1.1: Read in our data\n",
    "\n",
    "Is it a CSV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"WHERE IS YOUR FILE\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it a lot of separate files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import glob\n",
    "# filenames = glob.glob(\"*.txt\")\n",
    "# contents = [open(filename).read() for filename in filenames]\n",
    "# df = pd.DataFrame({\n",
    "#     'filename': filenames,\n",
    "#     'content': contents\n",
    "# })\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Or is just just some stuff you're typing in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Farmer</td>\n",
       "      <td>I work in the fields planting plants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pirate</td>\n",
       "      <td>I sail ships in the ocean doing ocean stuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pirate</td>\n",
       "      <td>The ocean life is the life for me! And I fight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pirate</td>\n",
       "      <td>I fight other ships for gold dubloons on the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Farmer</td>\n",
       "      <td>When the fields are full of plants I reap them...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      job                                               text\n",
       "0  Farmer               I work in the fields planting plants\n",
       "1  Pirate        I sail ships in the ocean doing ocean stuff\n",
       "2  Pirate  The ocean life is the life for me! And I fight...\n",
       "3  Pirate  I fight other ships for gold dubloons on the h...\n",
       "4  Farmer  When the fields are full of plants I reap them..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements = [\n",
    "    { 'job': \"Farmer\", 'text': \"I work in the fields planting plants\" },\n",
    "    { 'job': \"Pirate\", 'text': \"I sail ships in the ocean doing ocean stuff\" },\n",
    "    { 'job': \"Pirate\", 'text': \"The ocean life is the life for me! And I fight SHARKS.\" },\n",
    "    { 'job': \"Pirate\", 'text': \"I fight other ships for gold dubloons on the high seas\" },\n",
    "    { 'job': \"Farmer\", 'text': \"When the fields are full of plants I reap them and sell them at the market\" },\n",
    "    { 'job': \"Farmer\", 'text': \"I own a few fields of corn\" }\n",
    "]\n",
    "df = pd.DataFrame(elements)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.2: Creating a label column\n",
    "\n",
    "It needs to be a number, right? Before we just did \"does it contain Italian\" and make `True` be `1` and `False` be `0`, but most of the time we have **more than that.**\n",
    "\n",
    "Let's talk about `LabelEncoder`. It can `fit`, it can `transform`, and it can `fit_transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating features\n",
    "\n",
    "These need to be numbers, too, right?\n",
    "\n",
    "### Step 2.0: If you aren't analyzing text, you'll just move some columns into `features_df` like\n",
    "\n",
    "```\n",
    "features_df = df[['age','weight']]\n",
    "```\n",
    "\n",
    "### Step 2.1: If analyzing text, create your vectorizer\n",
    "\n",
    "Which kind of vectorizer are you using? A **CountVectorizer** to only count values, or a **TfIdfVectorizer** to count percentages? Once you've figured it out, answer the following questions.\n",
    "\n",
    "1. **vocabulary**: are you looking for a specific set of words? It's just a normal list.\n",
    "1. **ngram_range**: are you only vectorizing single words, or are you also looking at multi-word phrases? By default it only looks for one word `(1,1)`, but you can look for 1-2 word phrases `(1,2)`, only 4-word phrases `(4,4)`, etc.\n",
    "1. **binary**: Do you want to just test to see if a word is included or not, and don't care about counting? `True` or `False`.\n",
    "1. **tokenizer**: are you going to do any stemming or lemmatization, or are you okay with the existing words?\n",
    "1. **stop_words**: do you use stopwords? Stopwords are useless for judging content, but good for judging style. `english` will give default words, or use a list to use multiple.\n",
    "1. **max_df**: do you want to not include words that show up in a lot of documents? `0.0`-`1.0` to have a percentage as a ceiling, or an integer to have a maximum number of documents. For example, \"5\" means \"Ignore anything that shows up in more than 5 documents\" \n",
    "1. **min_df**: do you want to not include words that show up in a only a few documents? `0.0`-`1.0` to have a percentage as a floor, or an integer to have a maximum number of documents. For example, \"0.05\" means \"Ignore anything that shows up in fewer than 5% of documents\" \n",
    "1. **use_idf**: do you want to use inverse document frequency, which makes less frequent words more important? (`TfidfVectorizer` only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you build your vectorizer, this is where all of the options above go, like **stop_words** and **ngram_range**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "#vec = TfIdfVectorizer()\n",
    "matrix = vec.fit_transform(df.text)\n",
    "features_df = pd.DataFrame(matrix.toarray(), columns=vec.get_feature_names())\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Creating custom columns in addition to text\n",
    "\n",
    "First, you'll create a function for every feature you'd like to add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a very rough approximation, but it's going to be faster than using TextBlob\n",
    "def average_sentence_length(text):\n",
    "    # Split into sentences using periods, and words using spaces\n",
    "    sentences = text.split(\".\")\n",
    "    words = text.split(\" \")\n",
    "    return len(words) / len(sentences)\n",
    "\n",
    "# Let's test it while we're here\n",
    "sentence = \"This is an average sentence. And another.\"\n",
    "length = average_sentence_length(sentence)\n",
    "print(length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use `.apply` to run it for every row, and add it to `features_df`. Be sure to give it a **weird name** that won't overlap with your word counts! And when you do `.apply`, use `df.colname.apply` instead of `df.apply`, since your function takes the TEXT and not the ROW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_df['CUSTOM_sentence_length'] = df.text.apply(average_sentence_length)\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying\n",
    "\n",
    "### Step 3.1: Selecting and creating a classifier\n",
    "\n",
    "You have a few options! Generally you can try them all and pick the one that ends up working best.\n",
    "\n",
    "* **Multinominal Naive Bayes - (multiple numbers)**: You count the words. You care about whether a word appears once or twice or three times or ten times. *This is better for long passages*\n",
    "* **Bernoulli Naive Bayes - True/False Bayes:** You only care if the word shows up (`1`) or it doesn't show up (`0`) - *this is better for short passages*\n",
    "* **Decision Trees** are another kind of classifier. They can make fun charts. They don't care about whether things are correlated, which can be a problem for Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# What kind of classifier?\n",
    "# clf = BernoulliNB()\n",
    "# clf = MultinomialNB()\n",
    "# clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Train/test split\n",
    "\n",
    "Some data you'll train your classifier with, some you'll use for testing. That's how you know how good your model is!\n",
    "\n",
    "**You can only train and test on rows you know the answer to already.** Do you have 100,000 emails but only know what 2,000 of them are about? You'll need to **filter that first**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SANITY CHECK: What are your features?\n",
    "# They are probably in a separte df just for features, and they should be numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SANITY CHECK: What are your labels?\n",
    "# They're probably in your original dataframe, and they should be numbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now you're allowed to do your split. Once you know how this works you can delete all of the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_test_split will split our data into two parts\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting into...\n",
    "# X = are all our features\n",
    "# y = are all our labels\n",
    "# X_train are our features to train on (80%)\n",
    "# y_train are our labels to train on (80%)\n",
    "# X_test are our features to test on (20%)\n",
    "# y_train are our labels to test on (20%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "#    features_df.values,  # Is this what your features are?\n",
    "#    df.label, # Is this what your labels are?\n",
    "    test_size=0.2) \n",
    "\n",
    "# the first parameter is our FEATURES. It usually needs .values if it's a big dataframe\n",
    "# the second parameter is the LABEL as a number\n",
    "# 80% training, 20% testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.3: Fit and score your model\n",
    "\n",
    "Teach it what you know, and see how well did you did!\n",
    "\n",
    "First we'll **teach it with training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll **score with testing data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also check to see how well it does against data it's already seen, if you want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding your classifier\n",
    "\n",
    "### Method 1: Top words for each category\n",
    "\n",
    "This only works for Naive Bayes classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html\n",
    "import numpy as np\n",
    "\n",
    "le.classes_\n",
    "\n",
    "class_labels = le.classes_\n",
    "feature_names = vec.get_feature_names()\n",
    "for i, class_label in enumerate(class_labels):\n",
    "    try:\n",
    "        top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "        features_names = vec.get_feature_names()\n",
    "        print(\"%s: %s\" % (class_label, \" \".join(features_names[j] for j in top10)))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Draw the decision tree\n",
    "\n",
    "Decision tree only, of course. You probably ned to go back to when you made the tree and add `max_depth=3` or something to make it not get so big it won't display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pydotplus\n",
    "from IPython.display import Image  \n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "    feature_names=vec.get_feature_names(),  \n",
    "    class_names=clf.classes_.astype(str),  \n",
    "    filled=True, rounded=True,  proportion=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
