{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "df = pd.read_csv(\"wine-reviews.csv\")\n",
    "df['alcohol_int'] = df.alcohol.str.extract(\"(\\d+)\", expand=False).dropna().astype(int)\n",
    "df['price_int'] = df.price.str.extract(\"(\\d+)\", expand=False).dropna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3131, 6166) (783, 6166) (3131,) (783,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "#clean up data\n",
    "df.dropna(subset = ['price_int', 'wine_desc'], how = 'any', inplace = True)\n",
    "\n",
    "#token pattern changed from '\\b\\w\\w+\\b' (default) to '\\b[a-zA-Z][a-zA-Z]+\\b' to avoid data leak.\n",
    "#If the price were in the review, that would be easy to classify.\n",
    "vec = CountVectorizer(stop_words = 'english', token_pattern=r'\\b[a-zA-Z][a-zA-Z]+\\b')\n",
    "vec.fit(df['wine_desc'])\n",
    "X = vec.transform(df['wine_desc'])\n",
    "y = df['price_int']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on train: 0.999951508299 \n",
      "Mean Squared Error on train: 0.0359310124613\n",
      "R2 on test: -0.460617584327 \n",
      "Mean Squared Error on test: 1678.1136485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import  mean_squared_error, r2_score\n",
    "\n",
    "lr = LinearRegression(fit_intercept = 0)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print('R2 on train:', r2_score(y_train, lr.predict(X_train)), \n",
    "      '\\nMean Squared Error on train:', mean_squared_error(y_train, lr.predict(X_train)))\n",
    "\n",
    "print('R2 on test:', r2_score(y_test, lr.predict(X_test)), \n",
    "      '\\nMean Squared Error on test:', mean_squared_error(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier is great for interpolation, ie predicting prices based on reviews which lie within the set of reviews the model was trained on.  This is due to the varied vocabulary of the sommelier.  The model fails to extrapolate to the test set, also due to the varied nature of the vocabulary.  A negative R2 score reported by sklearn means the model performs arbitrarily worse than the mean price predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest Contributors to High Price\n",
      "\n",
      "defines 59.2786439226\n",
      "individual 63.8846518512\n",
      "burns 64.0996889334\n",
      "hallowed 65.5174628341\n",
      "boschis 67.2261551957\n",
      "parcel 70.4912873491\n",
      "powerhouse 73.3708244641\n",
      "blockbuster 78.0520539929\n",
      "maintaining 114.351774132\n",
      "constructed 130.595341103\n",
      "\n",
      "\n",
      "Largest Contributors to Low Price\n",
      "\n",
      "original -40.7203314284\n",
      "amplified -41.2685986525\n",
      "arrives -42.2709040748\n",
      "metallic -42.3623886854\n",
      "paso -42.9006997407\n",
      "integrates -43.2099850945\n",
      "kabinett -45.5336954914\n",
      "schisty -45.6498161539\n",
      "twice -48.0711291967\n",
      "reflects -48.5311801921\n",
      "numerous -55.3702689625\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    print('\\n--------------------------------\\n')\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % (topic_idx+1))\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "n = 10        \n",
    "bottom_n = np.argsort(lr.coef_)[n::-1]\n",
    "top_n = np.argsort(lr.coef_)[-n:]\n",
    "\n",
    "feature_names = vec.get_feature_names()\n",
    "\n",
    "print('Largest Contributors to High Price\\n')\n",
    "print(\"\\n\".join(feature_names[i] + \" \" + str(lr.coef_[i]) for i in top_n))\n",
    "\n",
    "print('\\n\\nLargest Contributors to Low Price\\n')\n",
    "print(\"\\n\".join(feature_names[i] + \" \" + str(lr.coef_[i]) for i in bottom_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
